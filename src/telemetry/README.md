# Telemetry Module

This module is responsible for logging application events and traces.

## Logging

The primary logging configuration is defined in `logger_config.py`. It utilizes Python's built-in `logging` module.

Key features:
- **Rotating Logs**: Logs are automatically rotated when they reach a certain size to prevent them from growing indefinitely. The `RotatingFileHandler` is used for this.
- **Log Level**: The default logging level is set to `INFO`. This can be configured in `logger_config.py`.
- **Log Format**: Logs include a timestamp, logger name, log level, and the message.

### How to Use the Logger

To use the logger in any module of your application, import the `get_logger` function from `logger_config.py`:

```python
from src.telemetry.logger_config import get_logger

# Get a logger instance specific to the current module
logger = get_logger(__name__)

# Example usage
logger.info("This is an informational message.")
logger.error("This is an error message.")
logger.warning("This is a warning message.")
logger.debug("This is a debug message (will not appear if level is INFO).")
```

### Using a Decorator for Tracing (Example)

While not implemented by default in `logger_config.py`, you can easily create a decorator to log function calls, arguments, and return values. Here's a conceptual example:

```python
import functools
from src.telemetry.logger_config import get_logger

# Assume logger is configured as above
trace_logger = get_logger("tracer")

def trace_function(func):
    @functools.wraps(func)
    def wrapper(*args, **kwargs):
        trace_logger.info(f"Calling function: {func.__name__} with args: {args}, kwargs: {kwargs}")
        try:
            result = func(*args, **kwargs)
            trace_logger.info(f"Function {func.__name__} returned: {result}")
            return result
        except Exception as e:
            trace_logger.error(f"Function {func.__name__} raised an exception: {e}", exc_info=True)
            raise
    return wrapper

# Example of using the decorator
# @trace_function
# def my_function(x, y):
#     return x + y
```
To use such a decorator, you would uncomment it and place `@trace_function` above the function definition you want to trace.

## Log Location and Reading

- **Log Files**: Application logs are stored in the `logs/` directory at the root of the project.
- **Main Log File**: The primary log file is `logs/app.log`.
- **Rotation**: When `app.log` reaches its maximum size (configured in `logger_config.py`), it is renamed to `app.log.1`, and a new `app.log` is created. This process continues with `app.log.2`, etc., up to the configured backup count.

### How to Read Logs

You can read the log files using any text editor or command-line tools like `cat`, `less`, or `tail`.

Example using `tail` to follow the log in real-time:
```bash
tail -f logs/app.log
```

To view older, rotated logs:
```bash
less logs/app.log.1
```

Logs are plain text and formatted for readability. Each line typically represents a single log event.

## Supabase Integration for Centralized Logging

In addition to local file logging, this module now supports sending log entries to a Supabase instance for centralized storage and analysis. This is handled by the `SupabaseHandler` logging handler.

### Setup and Configuration

To enable Supabase logging, you need to configure two environment variables:

-   `SUPABASE_URL`: The URL of your Supabase project.
-   `SUPABASE_KEY`: Your Supabase service role key (recommended for server-side logging to bypass RLS) or an anon key if your Row Level Security policies are configured accordingly.

These variables can be set directly in your environment or defined in a `.env` file in the project root, which will be automatically loaded. Refer to the main project `README.md` and `secrets.toml.example` for more details on secret management.

Example for `.env` or `secrets.toml` (under `[supabase]` section if using `secrets.toml` and an adapter to load it into env vars):
```
SUPABASE_URL="your_supabase_project_url"
SUPABASE_KEY="your_supabase_service_role_or_anon_key"
```

If these variables are correctly set, the `SupabaseHandler` will be automatically activated by `logger_config.py` and will start sending logs. If they are not set, logging will gracefully fall back to local file and console handlers only, without errors.

### Supabase Table for Logs

Logs are sent to a table typically named `log_entries` in your Supabase database. You need to create this table manually in your Supabase project.

**Example SQL for `log_entries` table:**
```sql
CREATE TABLE public.log_entries (
    id bigint NOT NULL GENERATED BY DEFAULT AS IDENTITY,
    created_at timestamp with time zone NOT NULL DEFAULT now(), -- Supabase default for row creation time
    timestamp timestamp with time zone, -- Actual log record timestamp (ISO format)
    level_name text,
    level_number integer,
    logger_name text,
    module text,
    filename text,
    line_number integer,
    function_name text,
    message text,         -- Fully formatted log message
    raw_message text,     -- Original log message before formatting
    exception_info text,  -- Stack trace, if any
    process_id bigint,
    thread_id bigint,
    thread_name text,
    CONSTRAINT log_entries_pkey PRIMARY KEY (id)
);

-- Optional: Indexes for commonly queried fields
CREATE INDEX idx_log_entries_timestamp ON public.log_entries (timestamp);
CREATE INDEX idx_log_entries_level_name ON public.log_entries (level_name);
CREATE INDEX idx_log_entries_logger_name ON public.log_entries (logger_name);
```

**Row Level Security (RLS):**
- If you are using the `service_role` key for `SUPABASE_KEY`, it bypasses RLS, and no additional policies are strictly needed on the `log_entries` table for insertion.
- If you are using an `anon` key or another restricted key, you must set up appropriate RLS policies to allow inserts into the `log_entries` table. For example:
  ```sql
  -- Allow anonymous users to insert into log_entries
  CREATE POLICY "Allow anon inserts for logging"
  ON public.log_entries
  FOR INSERT
  TO anon
  WITH CHECK (true);

  -- Example: Restrict select access to a specific role (e.g., 'service_role' or 'admin')
  CREATE POLICY "Allow admin read access to logs"
  ON public.log_entries
  FOR SELECT
  USING (auth.role() = 'service_role'); -- Adjust role as needed
  ```

### How it Works

The `logger_config.py` attempts to initialize the `SupabaseHandler`. If successful (i.e., credentials are valid and client connects), this handler is added to the root logger. The `SupabaseHandler` then takes each log record, formats it into a structured dictionary, and sends it to the specified table in Supabase using the `SupabaseTelemetryClient`.
