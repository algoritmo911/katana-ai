import telebot
import json # Still needed for mock message in voice handler, consider removing if mock is fully gone.
# Actually, json is used by telebot.types.Message for json_string. And potentially by OpenAI's library. Let's keep it.
import os
from pathlib import Path
from datetime import datetime
import openai # Added for Whisper API and GPT
from dotenv import load_dotenv # Added for loading .env file

# Load environment variables from .env file
load_dotenv()

# API Tokens and Bot Initialization
API_TOKEN = os.environ.get('TELEGRAM_API_TOKEN', '12345:dummytoken') # Dummy for local dev if not set
OPENAI_API_KEY = os.environ.get('OPENAI_API_KEY')

bot = telebot.TeleBot(API_TOKEN)

if OPENAI_API_KEY:
    openai.api_key = OPENAI_API_KEY
else:
    print("[CRITICAL] OPENAI_API_KEY not found in environment variables. Voice recognition and GPT features WILL NOT WORK.")
    # Consider exiting if OpenAI key is critical and not found, or providing a fallback mode.

# --- Logging Setup ---
LOG_DIR = Path('logs')
LOG_DIR.mkdir(parents=True, exist_ok=True)
TELEGRAM_LOG_FILE = LOG_DIR / 'telegram.log'

# Directory for storing temporary voice files
VOICE_FILE_DIR = Path('voice_temp') # This was correctly here
VOICE_FILE_DIR.mkdir(parents=True, exist_ok=True)


def log_to_file(message_text, filename=TELEGRAM_LOG_FILE):
    """Appends a message to the specified log file."""
    with open(filename, 'a', encoding='utf-8') as f:
        f.write(f"{datetime.utcnow().isoformat()} | {message_text}\n")

def log_local_bot_event(event_description):
    """Logs an event to the console and to the telegram.log file."""
    full_log_message = f"[BOT_EVENT] {event_description}"
    print(f"{datetime.utcnow().isoformat()} | {full_log_message}")
    log_to_file(full_log_message)

# --- GPT Interaction ---
def get_gpt_response(user_text: str) -> str:
    """
    Sends user_text to OpenAI GPT API and returns the response.
    """
    log_local_bot_event(f"Sending to GPT: '{user_text}'")
    if not OPENAI_API_KEY:
        log_local_bot_event("OpenAI API key not configured. Cannot get GPT response.")
        return "‚ö†Ô∏è GPTÊúçÂä°ÂΩìÂâç‰∏çÂèØÁî® (API key missing)."

    try:
        # Using a simple prompt, adjust as needed.
        # Consider adding context or system messages if required for better responses.
        response = openai.ChatCompletion.create(
            model="gpt-3.5-turbo", # Or "gpt-4" if available and preferred
            messages=[
                {"role": "system", "content": "You are a helpful assistant."},
                {"role": "user", "content": user_text}
            ]
        )
        gpt_response = response.choices[0].message.content.strip()
        log_local_bot_event(f"Received from GPT: '{gpt_response}'")
        return gpt_response
    except openai.APIError as e:
        log_local_bot_event(f"OpenAI API Error during GPT call: {e}")
        return f"ü§ñ –û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞—â–µ–Ω–∏–∏ –∫ –ò–ò: {e}"
    except Exception as e:
        log_local_bot_event(f"Unexpected error during GPT call: {e}")
        return "ü§ñ –ü—Ä–æ–∏–∑–æ—à–ª–∞ –Ω–µ–ø—Ä–µ–¥–≤–∏–¥–µ–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."


# --- Text Message Handler ---
@bot.message_handler(func=lambda message: True, content_types=['text'])
def handle_text_message(message):
    """Handles incoming text messages by sending them to GPT."""
    chat_id = message.chat.id
    text = message.text.strip()

    log_to_file(f"USER_MESSAGE | ChatID: {chat_id} | Text: \"{text}\"")
    log_local_bot_event(f"Received text message from {chat_id}: \"{text}\"")

    # System command handling
    if text.lower() == "/start":
        log_local_bot_event(f"Processing /start command for chat_id {chat_id}")
        # Basic welcome message, can be expanded.
        # Consider adding a prompt to the system message of get_gpt_response for /start if more dynamic welcome is needed.
        # For now, keeping it simple and local.
        start_message = (
            "üëã –ü—Ä–∏–≤–µ—Ç! –Ø –≤–∞—à –ò–ò-–∞—Å—Å–∏—Å—Ç–µ–Ω—Ç.\n"
            "–ü—Ä–æ—Å—Ç–æ –æ—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ —Å–æ–æ–±—â–µ–Ω–∏–µ –∏–ª–∏ –≥–æ–ª–æ—Å–æ–≤—É—é –∑–∞–º–µ—Ç–∫—É, –∏ —è –ø–æ—Å—Ç–∞—Ä–∞—é—Å—å –ø–æ–º–æ—á—å.\n\n"
            "–î–æ—Å—Ç—É–ø–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã:\n"
            "/help - –ü–æ–∫–∞–∑–∞—Ç—å —ç—Ç–æ —Å–æ–æ–±—â–µ–Ω–∏–µ\n"
            "/status - –ü—Ä–æ–≤–µ—Ä–∏—Ç—å –º–æ–π —Å—Ç–∞—Ç—É—Å"
        )
        bot.send_message(chat_id, start_message)
        log_to_file(f"SYSTEM_COMMAND | ChatID: {chat_id} | Command: /start | Response: \"{start_message}\"")
        return
    elif text.lower() == "/help":
        log_local_bot_event(f"Processing /help command for chat_id {chat_id}")
        help_message = (
            "–ö–∞–∫ —è –º–æ–≥—É –ø–æ–º–æ—á—å:\n"
            "- –û—Ç–ø—Ä–∞–≤—å—Ç–µ –º–Ω–µ –ª—é–±–æ–π —Ç–µ–∫—Å—Ç–æ–≤—ã–π –≤–æ–ø—Ä–æ—Å –∏–ª–∏ —É—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ.\n"
            "- –û—Ç–ø—Ä–∞–≤—å—Ç–µ –≥–æ–ª–æ—Å–æ–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ, —è –µ–≥–æ —Ä–∞—Å—à–∏—Ñ—Ä—É—é –∏ –æ—Ç–≤–µ—á—É.\n"
            "- /status: –ü—Ä–æ–≤–µ—Ä–∏—Ç—å, —Ä–∞–±–æ—Ç–∞—é –ª–∏ —è.\n"
            "- /start: –ü–æ–∫–∞–∑–∞—Ç—å –ø—Ä–∏–≤–µ—Ç—Å—Ç–≤–µ–Ω–Ω–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ.\n\n"
            "–Ø –∏—Å–ø–æ–ª—å–∑—É—é GPT –¥–ª—è –≥–µ–Ω–µ—Ä–∞—Ü–∏–∏ –æ—Ç–≤–µ—Ç–æ–≤, —Ç–∞–∫ —á—Ç–æ –ø—Ä–æ—Å—Ç–æ –≥–æ–≤–æ—Ä–∏—Ç–µ —Å–æ –º–Ω–æ–π –µ—Å—Ç–µ—Å—Ç–≤–µ–Ω–Ω–æ!"
        )
        bot.send_message(chat_id, help_message)
        log_to_file(f"SYSTEM_COMMAND | ChatID: {chat_id} | Command: /help | Response: \"{help_message}\"")
        return
    elif text.lower() == "/status":
        log_local_bot_event(f"Processing /status command for chat_id {chat_id}")
        status_message = "‚úÖ –Ø –≤ –ø–æ—Ä—è–¥–∫–µ –∏ –≥–æ—Ç–æ–≤ –∫ —Ä–∞–±–æ—Ç–µ!"
        if not OPENAI_API_KEY:
            status_message = "‚ö†Ô∏è –Ø —Ä–∞–±–æ—Ç–∞—é, –Ω–æ —Ñ—É–Ω–∫—Ü–∏—è –ò–ò –æ—Ç–∫–ª—é—á–µ–Ω–∞ (–ø—Ä–æ–±–ª–µ–º–∞ —Å API –∫–ª—é—á–æ–º)."
        bot.send_message(chat_id, status_message)
        log_to_file(f"SYSTEM_COMMAND | ChatID: {chat_id} | Command: /status | Response: \"{status_message}\"")
        return

    # If not a system command, proceed with GPT
    ai_response = get_gpt_response(text)
    log_to_file(f"AI_RESPONSE | ChatID: {chat_id} | Response: \"{ai_response}\"")
    bot.send_message(chat_id, ai_response)


# --- Voice Processing ---
def get_text_from_voice(voice_file_path: str) -> str | None:
    """
    Transcribes voice using OpenAI Whisper API.
    Returns the transcribed text or None if an error occurs.
    """
    if not OPENAI_API_KEY:
        log_local_bot_event("OpenAI API key not configured. Cannot process voice.")
        return None

    try:
        log_local_bot_event(f"Sending voice file {voice_file_path} to OpenAI Whisper API...")
        with open(voice_file_path, "rb") as audio_file:
            transcription = openai.Audio.transcribe("whisper-1", audio_file)
        text = transcription.get('text')
        if text:
            log_local_bot_event(f"Voice transcribed successfully: '{text}'")
            return text.strip()
        else:
            log_local_bot_event("Voice transcription returned no text.")
            return None
    except openai.APIError as e:
        log_local_bot_event(f"OpenAI API Error during voice transcription: {e}")
        return None
    except Exception as e:
        log_local_bot_event(f"Unexpected error during voice transcription: {e}")
        return None

# --- Voice Message Handler ---
VOICE_FILE_DIR = Path('voice_temp')
VOICE_FILE_DIR.mkdir(parents=True, exist_ok=True)

@bot.message_handler(content_types=['voice'])
def handle_voice_message(message):
    """Handles incoming voice messages."""
    chat_id = message.chat.id
    log_local_bot_event(f"Received voice message from {chat_id}. File ID: {message.voice.file_id}")

    if not OPENAI_API_KEY:
        bot.reply_to(message, "‚ö†Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–≤–∞–Ω–∏–µ –≥–æ–ª–æ—Å–∞ –Ω–µ –Ω–∞—Å—Ç—Ä–æ–µ–Ω–æ –Ω–∞ —Å–µ—Ä–≤–µ—Ä–µ.")
        log_local_bot_event("Voice recognition skipped: OpenAI API key not configured.")
        return

    try:
        file_info = bot.get_file(message.voice.file_id)
        downloaded_file = bot.download_file(file_info.file_path)

        # Save the downloaded file temporarily
        temp_voice_path = VOICE_FILE_DIR / f"{message.voice.file_id}.ogg" # Telegram voice notes are often in ogg format
        with open(temp_voice_path, 'wb') as new_file:
            new_file.write(downloaded_file)

        log_local_bot_event(f"Voice file saved temporarily to {temp_voice_path}")

        transcribed_text = get_text_from_voice(str(temp_voice_path))

        if transcribed_text:
            log_local_bot_event(f"Voice from {chat_id} transcribed to: '{transcribed_text}'")
            # Create a new message object that looks like a text message
            # This allows reusing the handle_text_message logic
            # Some attributes of message might not be perfectly replicated, but core ones for handle_text_message should be.
            # Important: telebot.types.Message is complex. We only mock what's needed.
            # A cleaner way might be to refactor handle_text_message to accept text directly.
            # For now, this approach minimizes changes to existing text handling.
            # No longer need to mock a message, just process the text.
            bot.reply_to(message, f"üó£Ô∏è –†–∞—Å–ø–æ–∑–Ω–∞–Ω–æ: \"{transcribed_text}\"")
            log_to_file(f"USER_MESSAGE (VOICE) | ChatID: {chat_id} | Transcribed: \"{transcribed_text}\"")

            # Directly send transcribed text to GPT processing
            ai_response = get_gpt_response(transcribed_text)
            log_to_file(f"AI_RESPONSE (from VOICE) | ChatID: {chat_id} | Response: \"{ai_response}\"")
            bot.send_message(chat_id, ai_response)

        else:
            bot.reply_to(message, "–ù–µ –ø–æ–Ω—è–ª, –ø–æ–≤—Ç–æ—Ä–∏, –ø–æ–∂–∞–ª—É–π—Å—Ç–∞. üéôÔ∏è –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–æ–∑–Ω–∞—Ç—å —Ä–µ—á—å.")
            log_local_bot_event(f"Transcription failed or returned empty for voice from {chat_id}")

    except Exception as e:
        bot.reply_to(message, "–ü—Ä–æ–∏–∑–æ—à–ª–∞ –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≥–æ–ª–æ—Å–æ–≤–æ–≥–æ —Å–æ–æ–±—â–µ–Ω–∏—è. üò•")
        log_local_bot_event(f"Error processing voice message from {chat_id}: {e}")
    finally:
        # Clean up the temporary file
        if 'temp_voice_path' in locals() and temp_voice_path.exists():
            try:
                os.remove(temp_voice_path)
                log_local_bot_event(f"Temporary voice file {temp_voice_path} deleted.")
            except OSError as e_os:
                log_local_bot_event(f"Error deleting temporary voice file {temp_voice_path}: {e_os}")


if __name__ == '__main__':
    log_local_bot_event("Bot starting...")
    bot.polling()
    log_local_bot_event("Bot stopped.")
