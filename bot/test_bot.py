import unittest
from unittest.mock import MagicMock, patch, call
import json
from pathlib import Path
import shutil # For robust directory removal
import os # Import os as it's used by patch.dict(os.environ, ...)
import logging # For checking log levels in tests

# Imports for NLP client testing
from nlp_services.base_nlp_client import NLPServiceError, NLPAuthenticationError # For simulating errors

# katana_bot will be imported in setUpClass after patching os.environ
katana_bot = None

class TestBot(unittest.TestCase):

    @classmethod
    def setUpClass(cls):
        cls.env_patcher = patch.dict(os.environ, {'KATANA_TELEGRAM_TOKEN': '123456:ABCDEF_mocked_for_tests'})
        cls.env_patcher.start()

        # Import katana_bot module here, after environment is patched
        global katana_bot # So that test methods can access it if they were using global
        from bot import katana_bot as kb_module
        cls.katana_bot = kb_module # Make it a class attribute
        katana_bot = kb_module # also update global if tests relied on it (less ideal)


    @classmethod
    def tearDownClass(cls):
        cls.env_patcher.stop()

    def setUp(self):
        # Create a dummy commands directory for testing
        self.test_commands_dir = Path("test_commands_temp_dir_bot") # Using a more unique name
        self.test_commands_dir.mkdir(parents=True, exist_ok=True)

        # Store original and set to test using cls.katana_bot
        self.original_command_file_dir = self.katana_bot.COMMAND_FILE_DIR
        katana_bot.COMMAND_FILE_DIR = self.test_commands_dir

        # Mock the bot object and its methods (already instantiated in the reloaded katana_bot)
        self.mock_bot_instance = MagicMock()
        # Patch the bot instance within the 'katana_bot' module (which is now self.katana_bot)
        self.bot_patcher = patch.object(self.katana_bot, 'bot', self.mock_bot_instance)
        self.mock_bot_module_instance = self.bot_patcher.start() # This is the mocked bot instance

        # Mock datetime to control timestamps in filenames
        self.mock_datetime_patcher = patch.object(self.katana_bot, 'datetime')
        self.mock_datetime = self.mock_datetime_patcher.start()
        self.mock_datetime.utcnow.return_value.strftime.return_value = "YYYYMMDD_HHMMSS_ffffff"


    def tearDown(self):
        # Stop patchers
        self.bot_patcher.stop()
        self.mock_datetime_patcher.stop()

        # Clean up: remove dummy directory and its contents
        if self.test_commands_dir.exists():
            shutil.rmtree(self.test_commands_dir)

        # Restore original using cls.katana_bot
        self.katana_bot.COMMAND_FILE_DIR = self.original_command_file_dir


    def _create_mock_message(self, text_payload):
        mock_message = MagicMock()
        mock_message.chat.id = 12345
        mock_message.text = json.dumps(text_payload)
        return mock_message

    # --- Test Command Validation ---
    def test_valid_command_gets_saved(self):
        command = {"type": "test_type", "module": "test_module", "args": {}, "id": "test_id"}
        mock_message = self._create_mock_message(command)
        
        self.katana_bot.handle_message(mock_message)
        
        # Check file creation
        expected_module_dir = self.test_commands_dir / "telegram_mod_test_module"
        self.assertTrue(expected_module_dir.exists())
        
        expected_filename = f"YYYYMMDD_HHMMSS_ffffff_{mock_message.chat.id}.json"
        expected_file_path = expected_module_dir / expected_filename
        self.assertTrue(expected_file_path.exists())

        with open(expected_file_path, "r") as f:
            saved_data = json.load(f)
        self.assertEqual(saved_data, command)

        # Check reply
        self.mock_bot_module_instance.reply_to.assert_called_once()
        args, kwargs = self.mock_bot_module_instance.reply_to.call_args
        self.assertEqual(args[0], mock_message)
        self.assertTrue(args[1].startswith("‚úÖ Command received and saved as"))
        self.assertIn(str(expected_file_path), args[1])


    def test_invalid_json_format(self):
        mock_message = MagicMock() # Simpler mock for this case
        mock_message.chat.id = 123
        mock_message.text = "not a valid json"
        self.katana_bot.handle_message(mock_message)
        self.mock_bot_module_instance.reply_to.assert_called_with(mock_message, "‚ùå Error: Invalid JSON format.")

    def test_missing_type_field(self):
        command = {"module": "test_module", "args": {}, "id": "test_id"} # type is missing
        mock_message = self._create_mock_message(command)
        self.katana_bot.handle_message(mock_message)
        self.mock_bot_module_instance.reply_to.assert_called_with(mock_message, "‚ùå Error: Missing required field 'type'.")

    def test_invalid_args_type(self):
        command = {"type": "test_type", "module": "test_module", "args": "not_a_dict", "id": "test_id"}
        mock_message = self._create_mock_message(command)
        self.katana_bot.handle_message(mock_message)
        self.mock_bot_module_instance.reply_to.assert_called_with(mock_message, "‚ùå Error: Field 'args' must be type dict. Got str.")

    def test_invalid_id_type(self):
        command = {"type": "test_type", "module": "test_module", "args": {}, "id": [1,2,3]} # id is a list
        mock_message = self._create_mock_message(command)
        self.katana_bot.handle_message(mock_message)
        self.mock_bot_module_instance.reply_to.assert_called_with(mock_message, "‚ùå Error: Field 'id' must be type str or int. Got list.")


    # --- Test Command Routing ---
    @patch('bot.katana_bot.handle_log_event') # –£–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
    def test_routing_log_event(self, mock_handle_log_event_func):
        command = {"type": "log_event", "module": "logging", "args": {"message": "hello"}, "id": "log001"}
        mock_message = self._create_mock_message(command)

        self.katana_bot.handle_message(mock_message)

        mock_handle_log_event_func.assert_called_once_with(command, mock_message.chat.id)
        self.mock_bot_module_instance.reply_to.assert_called_with(mock_message, "‚úÖ 'log_event' processed (placeholder).")


    @patch('bot.katana_bot.handle_mind_clearing') # –£–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
    def test_routing_mind_clearing(self, mock_handle_mind_clearing_func):
        command = {"type": "mind_clearing", "module": "wellness", "args": {"duration": "10m"}, "id": "mind002"}
        mock_message = self._create_mock_message(command)

        self.katana_bot.handle_message(mock_message)
        
        mock_handle_mind_clearing_func.assert_called_once_with(command, mock_message.chat.id)
        self.mock_bot_module_instance.reply_to.assert_called_with(mock_message, "‚úÖ 'mind_clearing' processed (placeholder).")

    # --- Test NLP and Logging Integration (Initial Structure) ---

    @patch('bot.katana_bot.log_local_bot_event') # Mocking the logger to check calls
    @patch('bot.katana_bot.handle_nlp_command', create=True) # –ú–æ–∫–∞–µ–º –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π –æ–±—Ä–∞–±–æ—Ç—á–∏–∫ NLP –∫–æ–º–∞–Ω–¥, —Å–æ–∑–¥–∞–µ–º –µ—Å–ª–∏ –Ω–µ—Ç
    def test_nlp_command_integration(self, mock_handle_nlp_command, mock_log_local_bot_event):
        # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ –∫–æ–º–∞–Ω–¥–∞ —Å type="nlp_process" –±—É–¥–µ—Ç –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞—Ç—å—Å—è —Ñ—É–Ω–∫—Ü–∏–µ–π handle_nlp_command
        # –≠—Ç—É —Ñ—É–Ω–∫—Ü–∏—é –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —Å–æ–∑–¥–∞—Ç—å –≤ katana_bot.py
        # katana_bot.py –Ω—É–∂–Ω–æ –±—É–¥–µ—Ç –¥–æ—Ä–∞–±–æ—Ç–∞—Ç—å, —á—Ç–æ–±—ã –∏–º–µ—Ç—å nlp_processor (–∏–ª–∏ –≤—ã–∑—ã–≤–∞—Ç—å —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏–π —Å–µ—Ä–≤–∏—Å)

        # mock_handle_nlp_command - —ç—Ç–æ –º–æ–∫ –¥–ª—è —Ñ—É–Ω–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –¥–æ–ª–∂–Ω–∞ –±—ã–ª–∞ –±—ã –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å NLP –∫–æ–º–∞–Ω–¥—É.
        # –ù–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç –º—ã –Ω–µ –±—É–¥–µ–º –Ω–∞—Å—Ç—Ä–∞–∏–≤–∞—Ç—å –µ–≥–æ return_value, —Ç–∞–∫ –∫–∞–∫
        # –æ—Å–Ω–æ–≤–Ω–∞—è —Ü–µ–ª—å —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞ - –ø—Ä–æ–≤–µ—Ä–∏—Ç—å, —á—Ç–æ –æ–Ω –ù–ï –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è,
        # –ø–æ–∫–∞ —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∞—è –ª–æ–≥–∏–∫–∞ –º–∞—Ä—à—Ä—É—Ç–∏–∑–∞—Ü–∏–∏ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ katana_bot.py.
        # –ü–æ–∑–∂–µ, –∫–æ–≥–¥–∞ –ª–æ–≥–∏–∫–∞ –±—É–¥–µ—Ç –¥–æ–±–∞–≤–ª–µ–Ω–∞, –º—ã –±—É–¥–µ–º –ø—Ä–æ–≤–µ—Ä—è—Ç—å –µ–≥–æ –≤—ã–∑–æ–≤ –∏ —Ä–µ–∑—É–ª—å—Ç–∞—Ç.

        command_text = "–ü—Ä–æ–∞–Ω–∞–ª–∏–∑–∏—Ä—É–π —ç—Ç–æ—Ç —Ç–µ–∫—Å—Ç" # –≠—Ç–æ—Ç —Ç–µ–∫—Å—Ç –ø–æ–∫–∞ –Ω–µ –∏—Å–ø–æ–ª—å–∑—É–µ—Ç—Å—è –Ω–∞–ø—Ä—è–º—É—é –≤ —ç—Ç–æ–º —Ç–µ—Å—Ç–µ
        command_payload = {
            "type": "nlp_process",
            "module": "nlp",
            "args": {"text": command_text},
            "id": "nlp001"
        }
        mock_message = self._create_mock_message(command_payload)

        # –ü—Ä–µ–¥–ø–æ–ª–æ–∂–∏–º, —á—Ç–æ handle_message –±—É–¥–µ—Ç –≤—ã–∑—ã–≤–∞—Ç—å nlp_processor.process_text
        # –∏ –∑–∞—Ç–µ–º –æ—Ç–≤–µ—á–∞—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç–æ–º. –≠—Ç–æ –ø–æ—Ç—Ä–µ–±—É–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∏–π –≤ bot.py

        # –î–ª—è —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞, –º—ã —Å–Ω–∞—á–∞–ª–∞ –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –µ—Å–ª–∏ —Ç–∞–∫–æ–π —Ç–∏–ø –∫–æ–º–∞–Ω–¥—ã –ù–ï –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ,
        # –æ–Ω —Å–æ—Ö—Ä–∞–Ω–∏—Ç—Å—è –∫–∞–∫ –æ–±—ã—á–Ω–æ. –ü–æ–∑–∂–µ, –∫–æ–≥–¥–∞ bot.py –±—É–¥–µ—Ç –æ–±–Ω–æ–≤–ª–µ–Ω, —ç—Ç–æ—Ç —Ç–µ—Å—Ç –∏–∑–º–µ–Ω–∏—Ç—Å—è.
        # –°–µ–π—á–∞—Å –º—ã –ø—Ä–æ—Å—Ç–æ –ø—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ nlp_processor –∏ logger –≤—ã–∑—ã–≤–∞—é—Ç—Å—è (–≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏).

        # --- –ù–∞—á–∞–ª–æ —Å–µ–∫—Ü–∏–∏, –∫–æ—Ç–æ—Ä–∞—è –±—É–¥–µ—Ç –∏–∑–º–µ–Ω–µ–Ω–∞ –ø–æ—Å–ª–µ –æ–±–Ω–æ–≤–ª–µ–Ω–∏—è bot.py ---
        # –í —Ç–µ–∫—É—â–µ–π —Ä–µ–∞–ª–∏–∑–∞—Ü–∏–∏ bot.py, –ª—é–±–∞—è –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç—Å—è.
        # –ü–æ—ç—Ç–æ–º—É –º—ã –æ–∂–∏–¥–∞–µ–º —Ç–∞–∫–æ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ –°–ï–ô–ß–ê–°.

        # –î–ª—è –∏–º–∏—Ç–∞—Ü–∏–∏ —Ç–æ–≥–æ, —á—Ç–æ NLP –º–æ–¥—É–ª—å –±—É–¥–µ—Ç –≤—ã–∑–≤–∞–Ω, –∏ –ª–æ–≥–≥–µ—Ä —Ç–æ–∂–µ,
        # –º—ã —Å–¥–µ–ª–∞–µ–º mock-–≤—ã–∑–æ–≤—ã –≤–Ω—É—Ç—Ä–∏ —ç—Ç–æ–≥–æ —Ç–µ—Å—Ç–∞, –∫–∞–∫ –µ—Å–ª–∏ –±—ã katana_bot.py –∏—Ö –¥–µ–ª–∞–ª.
        # –≠—Ç–æ –Ω–µ –∏–¥–µ–∞–ª—å–Ω—ã–π –∏–Ω—Ç–µ–≥—Ä–∞—Ü–∏–æ–Ω–Ω—ã–π —Ç–µ—Å—Ç, –Ω–æ –æ–Ω –≥–æ—Ç–æ–≤–∏—Ç –ø–æ—á–≤—É.

        # –ï—Å–ª–∏ –±—ã katana_bot.py –±—ã–ª –æ–±–Ω–æ–≤–ª–µ–Ω –¥–ª—è –æ–±—Ä–∞–±–æ—Ç–∫–∏ 'nlp_process' –∏ –≤—ã–∑—ã–≤–∞–ª handle_nlp_command:
        # katana_bot.handle_message(mock_message)
        # mock_handle_nlp_command.assert_called_once_with(command_payload, mock_message.chat.id)
        # # –î–∞–ª—å–Ω–µ–π—à–∏–µ –ø—Ä–æ–≤–µ—Ä–∫–∏ –æ—Ç–≤–µ—Ç–∞ –∏ –ª–æ–≥–æ–≤, —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω—ã—Ö –¥–ª—è NLP
        # --- –ö–æ–Ω–µ—Ü —Å–µ–∫—Ü–∏–∏ ---

        # –¢–ï–ö–£–©–ï–ï –ü–û–í–ï–î–ï–ù–ò–ï:
        # –ü–æ—Å–∫–æ–ª—å–∫—É katana_bot.py –ï–©–ï –ù–ï –ò–ú–ï–ï–¢ —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ–≥–æ –æ–±—Ä–∞–±–æ—Ç—á–∏–∫–∞ –¥–ª—è 'nlp_process'
        # –∏ –Ω–µ –≤—ã–∑—ã–≤–∞–µ—Ç –≥–∏–ø–æ—Ç–µ—Ç–∏—á–µ—Å–∫–∏–π 'handle_nlp_command',
        # –∫–æ–º–∞–Ω–¥–∞ 'nlp_process' –±—É–¥–µ—Ç –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ –∫–∞–∫ –Ω–µ–∏–∑–≤–µ—Å—Ç–Ω–∞—è –∫–æ–º–∞–Ω–¥–∞ –∏ –ø—Ä–æ—Å—Ç–æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞.
        # –ü–æ—ç—Ç–æ–º—É mock_handle_nlp_command –ù–ï –ë–£–î–ï–¢ –≤—ã–∑–≤–∞–Ω.
        self.katana_bot.handle_message(mock_message)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –±—ã–ª–∞ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞ (—Ç–µ–∫—É—â–µ–µ –ø–æ–≤–µ–¥–µ–Ω–∏–µ)
        expected_module_dir = self.test_commands_dir / "telegram_mod_nlp"
        self.assertTrue(expected_module_dir.exists(), "–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –¥–ª—è NLP –º–æ–¥—É–ª—è –¥–æ–ª–∂–Ω–∞ –±—ã—Ç—å —Å–æ–∑–¥–∞–Ω–∞")
        expected_filename = f"YYYYMMDD_HHMMSS_ffffff_{mock_message.chat.id}.json"
        expected_file_path = expected_module_dir / expected_filename
        self.assertTrue(expected_file_path.exists(), "–§–∞–π–ª –∫–æ–º–∞–Ω–¥—ã NLP –¥–æ–ª–∂–µ–Ω –±—ã—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω")

        with open(expected_file_path, "r") as f:
            saved_data = json.load(f)
        self.assertEqual(saved_data, command_payload, "–°–æ—Ö—Ä–∞–Ω–µ–Ω–Ω—ã–µ –¥–∞–Ω–Ω—ã–µ –∫–æ–º–∞–Ω–¥—ã NLP –Ω–µ —Å–æ–≤–ø–∞–¥–∞—é—Ç")

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –±–æ—Ç –æ—Ç–≤–µ—Ç–∏–ª –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏
        self.mock_bot_module_instance.reply_to.assert_called_with(
            mock_message,
            f"‚úÖ Command received and saved as `{str(expected_file_path)}`."
        )

        # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ mock_handle_nlp_command –ù–ï –±—ã–ª –≤—ã–∑–≤–∞–Ω, —Ç–∞–∫ –∫–∞–∫ –ª–æ–≥–∏–∫–∞ –µ—â–µ –Ω–µ –¥–æ–±–∞–≤–ª–µ–Ω–∞ –≤ katana_bot.py
        mock_handle_nlp_command.assert_not_called()

        # –ü—Ä–æ–≤–µ—Ä–∏–º –æ—Å–Ω–æ–≤–Ω—ã–µ –ª–æ–≥–∏ (–ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è, —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ)
        # –≠—Ç–æ –¥—É–±–ª–∏—Ä—É–µ—Ç —á–∞—Å—Ç—å test_logging_on_standard_command, –Ω–æ –∑–¥–µ—Å—å –≤ –∫–æ–Ω—Ç–µ–∫—Å—Ç–µ NLP –∫–æ–º–∞–Ω–¥—ã,
        # –∫–æ—Ç–æ—Ä–∞—è –ø–æ–∫–∞ –æ–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç—Å—è –ø–æ —Å—Ç–∞–Ω–¥–∞—Ä—Ç–Ω–æ–º—É –ø—É—Ç–∏.
        actual_log_calls = [call_item[0][0] for call_item in mock_log_local_bot_event.call_args_list if call_item[0]]
        self.assertIn(f"Received message from {mock_message.chat.id}: {mock_message.text}", actual_log_calls)
        self.assertIn(f"Command type 'nlp_process' with module 'nlp' not specifically handled by NLP, proceeding with default save.", actual_log_calls) # Updated expected log
        self.assertIn(f"Saved command from {mock_message.chat.id} to {str(expected_file_path)}", actual_log_calls)


    @patch('bot.katana_bot.log_local_bot_event') # –£–∫–∞–∑—ã–≤–∞–µ–º –ø–æ–ª–Ω—ã–π –ø—É—Ç—å
    def test_logging_on_standard_command(self, mock_log_local_bot_event):
        command = {"type": "test_log", "module": "logging_test", "args": {}, "id": "log_test_001"}
        mock_message = self._create_mock_message(command)

        self.katana_bot.handle_message(mock_message)

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ –æ—Å–Ω–æ–≤–Ω—ã–µ –ª–æ–≥-—Å–æ–æ–±—â–µ–Ω–∏—è –≤—ã–∑—ã–≤–∞—é—Ç—Å—è
        # –ü–µ—Ä–≤–æ–µ —Å–æ–æ–±—â–µ–Ω–∏–µ - –ø–æ–ª—É—á–µ–Ω–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è
        # –í—Ç–æ—Ä–æ–µ - –≤–∞–ª–∏–¥–∞—Ü–∏—è (–µ—Å–ª–∏ –±—ã –±—ã–ª–∏ –æ—à–∏–±–∫–∏, –±—ã–ª–∏ –±—ã –¥—Ä—É–≥–∏–µ —Å–æ–æ–±—â–µ–Ω–∏—è)
        # –¢—Ä–µ—Ç—å–µ - –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ –∫–æ–º–∞–Ω–¥—ã
        # –ß–µ—Ç–≤–µ—Ä—Ç–æ–µ (–≤–æ–∑–º–æ–∂–Ω–æ) - –æ —Ç–æ–º, —á—Ç–æ —Ç–∏–ø –∫–æ–º–∞–Ω–¥—ã –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω —Å–ø–µ—Ü–∏–∞–ª—å–Ω–æ (–µ—Å–ª–∏ —ç—Ç–æ —Ç–∞–∫)

        # –¢–æ—á–Ω—ã–µ –≤—ã–∑–æ–≤—ã –∑–∞–≤–∏—Å—è—Ç –æ—Ç –ø—É—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è –≤ handle_message.
        # –ú—ã –æ–∂–∏–¥–∞–µ–º –∫–∞–∫ –º–∏–Ω–∏–º—É–º –ª–æ–≥ –æ –ø–æ–ª—É—á–µ–Ω–∏–∏ –∏ –ª–æ–≥ –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏.

        # –ü—Ä–∏–º–µ—Ä–Ω—ã–µ –æ–∂–∏–¥–∞–µ–º—ã–µ –≤—ã–∑–æ–≤—ã (–Ω—É–∂–Ω–æ –±—É–¥–µ—Ç —É—Ç–æ—á–Ω–∏—Ç—å –Ω–∞ –æ—Å–Ω–æ–≤–µ —Ä–µ–∞–ª—å–Ω—ã—Ö –ª–æ–≥–æ–≤ bot.py)
        # expected_calls = [
        #     call(f"Received message from {mock_message.chat.id}: {mock_message.text}"),
        #     call(f"Command type 'test_log' with module 'logging_test' not specifically handled by NLP, proceeding with default save."),
        #     call(f"Saved command from {mock_message.chat.id} to {self.test_commands_dir / 'telegram_mod_logging_test' / f'YYYYMMDD_HHMMSS_ffffff_{mock_message.chat.id}.json'}")
        # ]

        # –ü—Ä–æ–≤–µ—Ä—è–µ–º, —á—Ç–æ —ç—Ç–∏ –≤—ã–∑–æ–≤—ã –±—ã–ª–∏ —Å—Ä–µ–¥–∏ –≤—Å–µ—Ö –≤—ã–∑–æ–≤–æ–≤ –∫ –ª–æ–≥–≥–µ—Ä—É
        # –ò—Å–ø–æ–ª—å–∑—É–µ–º list(mock_log_local_bot_event.mock_calls) –¥–ª—è –æ—Ç–ª–∞–¥–∫–∏ –µ—Å–ª–∏ –Ω—É–∂–Ω–æ
        # print(list(mock_log_local_bot_event.mock_calls))

        # –ü—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω—ã–µ –≤—ã–∑–æ–≤—ã –±—ã–ª–∏ —Å–¥–µ–ª–∞–Ω—ã. –ü–æ—Ä—è–¥–æ–∫ –º–æ–∂–µ—Ç –∏–º–µ—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ.
        # –í –¥–∞–Ω–Ω–æ–º —Å–ª—É—á–∞–µ, –º—ã –∑–Ω–∞–µ–º, —á—Ç–æ `log_local_bot_event` –≤—ã–∑—ã–≤–∞–µ—Ç—Å—è –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑.
        # –ú—ã –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –æ–∂–∏–¥–∞–µ–º—ã–µ –≤—ã–∑–æ–≤—ã –ø—Ä–∏—Å—É—Ç—Å—Ç–≤—É—é—Ç.

        # –ß—Ç–æ–±—ã —Å–¥–µ–ª–∞—Ç—å –ø—Ä–æ–≤–µ—Ä–∫—É –±–æ–ª–µ–µ –Ω–∞–¥–µ–∂–Ω–æ–π, –º–æ–∂–Ω–æ –ø—Ä–æ–≤–µ—Ä–∏—Ç—å –Ω–∞–ª–∏—á–∏–µ –ø–æ–¥—Å—Ç—Ä–æ–∫ –≤ –≤—ã–∑–æ–≤–∞—Ö,
        # –µ—Å–ª–∏ —Ç–æ—á–Ω—ã–µ —Å–æ–æ–±—â–µ–Ω–∏—è –º–æ–≥—É—Ç –Ω–µ–º–Ω–æ–≥–æ –º–µ–Ω—è—Ç—å—Å—è.

        # –ù–∞ –¥–∞–Ω–Ω—ã–π –º–æ–º–µ–Ω—Ç, –ø—Ä–æ–≤–µ—Ä–∏–º, —á—Ç–æ –±–æ—Ç –æ—Ç–≤–µ—Ç–∏–ª –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏ (—ç—Ç–æ –∫–æ—Å–≤–µ–Ω–Ω–æ –≥–æ–≤–æ—Ä–∏—Ç –æ –ø—É—Ç–∏ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏—è)
        expected_module_dir = self.test_commands_dir / "telegram_mod_logging_test"
        expected_filename = f"YYYYMMDD_HHMMSS_ffffff_{mock_message.chat.id}.json"
        expected_file_path = expected_module_dir / expected_filename
        self.assertTrue(expected_file_path.exists()) # –£–±–µ–¥–∏–º—Å—è, —á—Ç–æ —Ñ–∞–π–ª —Å–æ—Ö—Ä–∞–Ω–µ–Ω

        self.mock_bot_module_instance.reply_to.assert_called_once()
        args, kwargs = self.mock_bot_module_instance.reply_to.call_args
        self.assertTrue(args[1].startswith("‚úÖ Command received and saved as"))

        # –ü—Ä–æ–≤–µ—Ä–∫–∞ –≤—ã–∑–æ–≤–æ–≤ –ª–æ–≥–≥–µ—Ä–∞:
        # –ú—ã –¥–æ–ª–∂–Ω—ã —É–≤–∏–¥–µ—Ç—å –ª–æ–≥ –æ –ø–æ–ª—É—á–µ–Ω–∏–∏ —Å–æ–æ–±—â–µ–Ω–∏—è –∏ –ª–æ–≥ –æ —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏–∏.
        # –¢–∞–∫–∂–µ –ª–æ–≥ –æ —Ç–æ–º, —á—Ç–æ –∫–æ–º–∞–Ω–¥–∞ –Ω–µ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–∞ —Å–ø–µ—Ü–∏—Ñ–∏—á–Ω–æ.

        # –û—Ç–ª–∞–¥–æ—á–Ω—ã–π –≤—ã–≤–æ–¥
        # print("mock_log_local_bot_event.call_args_list:", mock_log_local_bot_event.call_args_list)
        # print("mock_log_local_bot_event.mock_calls:", mock_log_local_bot_event.mock_calls)

        # –ü–æ–ª—É—á–∞–µ–º –≤—Å–µ —Ñ–∞–∫—Ç–∏—á–µ—Å–∫–∏–µ –≤—ã–∑–æ–≤—ã –∫ –º–æ–∫—É
        actual_log_calls = [call_item[0][0] for call_item in mock_log_local_bot_event.call_args_list if call_item[0]]

        self.assertIn(f"Received message from {mock_message.chat.id}: {mock_message.text}", actual_log_calls)
        self.assertIn(f"Command type 'test_log' with module 'logging_test' not specifically handled by NLP, proceeding with default save.", actual_log_calls) # Updated expected log
        self.assertIn(f"Saved command from {mock_message.chat.id} to {str(expected_file_path)}", actual_log_calls)

    # --- Tests for NLP Integration ---

    @patch('bot.katana_bot.get_anthropic_chat_response')
    @patch('bot.katana_bot.log_local_bot_event') # To verify logging
    def test_handle_message_anthropic_chat_success(self, mock_log_event, mock_get_anthropic_response):
        # Setup mock for NLP client
        mock_get_anthropic_response.return_value = "Anthropic says hello!"

        command_payload = {
            "type": "chat_query", # Type can be generic if module defines action
            "module": "anthropic_chat",
            "args": {
                "prompt": "Hello Anthropic",
                "history": [{"role": "user", "content": "Previous q"}],
                "model_name": "claude-test-model",
                "system_prompt": "Be brief.",
                "max_tokens": 50
            },
            "id": "anthropic001"
        }
        mock_message = self._create_mock_message(command_payload)

        # Call the handler
        self.katana_bot.handle_message(mock_message)

        # Verify NLP client was called correctly
        mock_get_anthropic_response.assert_called_once_with(
            history=command_payload["args"]["history"],
            user_prompt=command_payload["args"]["prompt"],
            model_name="claude-test-model",
            system_prompt="Be brief.",
            max_tokens_to_sample=50
        )

        # Verify bot reply
        self.mock_bot_module_instance.reply_to.assert_called_once_with(
            mock_message,
            "ü§ñ: Anthropic says hello!"
        )

        # Verify logging (simplified check)
        # Convert call_args_list to a list of the first argument of each call
        log_messages = [args[0] for args, kwargs in mock_log_event.call_args_list]
        self.assertIn(f"Processing 'anthropic_chat' for {mock_message.chat.id}. Prompt: '{command_payload['args']['prompt'][:50]}...'", log_messages)
        self.assertIn(f"Successfully replied to 'anthropic_chat' for {mock_message.chat.id}. Response: '{mock_get_anthropic_response.return_value[:50]}...'", log_messages)

    @patch('bot.katana_bot.get_openai_chat_response')
    @patch('bot.katana_bot.log_local_bot_event')
    def test_handle_message_openai_chat_success(self, mock_log_event, mock_get_openai_response):
        mock_get_openai_response.return_value = "OpenAI says hello!"

        command_payload = {
            "type": "chat_query",
            "module": "openai_chat",
            "args": {
                "prompt": "Hello OpenAI",
                "history": [],
                "model_name": "gpt-test-model",
                "system_prompt": "Be very helpful.",
                "max_tokens": 100
            },
            "id": "openai001"
        }
        mock_message = self._create_mock_message(command_payload)
        self.katana_bot.handle_message(mock_message)

        mock_get_openai_response.assert_called_once_with(
            history=[],
            user_prompt="Hello OpenAI",
            model_name="gpt-test-model",
            system_prompt="Be very helpful.",
            max_tokens=100
        )
        self.mock_bot_module_instance.reply_to.assert_called_once_with(
            mock_message,
            "ü§ñ: OpenAI says hello!"
        )
        log_messages = [args[0] for args, kwargs in mock_log_event.call_args_list]
        self.assertIn(f"Processing 'openai_chat' for {mock_message.chat.id}. Prompt: '{command_payload['args']['prompt'][:50]}...'", log_messages)
        self.assertIn(f"Successfully replied to 'openai_chat' for {mock_message.chat.id}. Response: '{mock_get_openai_response.return_value[:50]}...'", log_messages)

    @patch('bot.katana_bot.get_anthropic_chat_response')
    @patch('bot.katana_bot.log_local_bot_event')
    def test_handle_message_anthropic_chat_nlp_error(self, mock_log_event, mock_get_anthropic_response):
        # Simulate an NLPServiceError from the client
        error_user_message = "Anthropic —Å–µ—Ä–≤–∏—Å –≤—Ä–µ–º–µ–Ω–Ω–æ –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
        simulated_error = NLPAuthenticationError( # Using a specific child for variety
            message="Original Anthropic Auth Error",
            original_error=Exception("Original low-level exception"), # Mock original error
            user_message=error_user_message
        )
        mock_get_anthropic_response.side_effect = simulated_error

        command_payload = {
            "type": "chat_query",
            "module": "anthropic_chat",
            "args": {"prompt": "Hello failed Anthropic"},
            "id": "anthropic_err_001"
        }
        mock_message = self._create_mock_message(command_payload)
        self.katana_bot.handle_message(mock_message)

        mock_get_anthropic_response.assert_called_once() # Check it was called

        # Verify bot replies with the user_message from the exception
        self.mock_bot_module_instance.reply_to.assert_called_once_with(
            mock_message,
            f"ü§ñ‚ö†Ô∏è: {error_user_message}"
        )

        # Verify error logging
        # Check that an error was logged containing parts of the NLPServiceError's message
        error_log_found = False
        for call_args, call_kwargs in mock_log_event.call_args_list:
            log_message = call_args[0]
            log_level = call_kwargs.get('level')
            if log_level == logging.ERROR and "NLP Error for module anthropic_chat" in log_message and "Original Anthropic Auth Error" in log_message:
                self.assertTrue(call_kwargs.get('exc_info', False), "exc_info should be True for original_error logging")
                error_log_found = True
                break
        self.assertTrue(error_log_found, "Specific NLP error log message not found.")

    @patch('bot.katana_bot.get_openai_chat_response')
    @patch('bot.katana_bot.log_local_bot_event')
    def test_handle_message_openai_chat_nlp_error(self, mock_log_event, mock_get_openai_response):
        error_user_message = "OpenAI —Å–µ—Ä–≤–∏—Å —Å–µ–π—á–∞—Å –Ω–µ–¥–æ—Å—Ç—É–ø–µ–Ω."
        simulated_error = NLPServiceError( # Using the base class here
            message="Original OpenAI Some Error",
            original_error=RuntimeError("Original runtime error from OpenAI client"),
            user_message=error_user_message
        )
        mock_get_openai_response.side_effect = simulated_error

        command_payload = {
            "type": "chat_query",
            "module": "openai_chat",
            "args": {"prompt": "Hello failed OpenAI"},
            "id": "openai_err_001"
        }
        mock_message = self._create_mock_message(command_payload)
        self.katana_bot.handle_message(mock_message)

        mock_get_openai_response.assert_called_once()

        self.mock_bot_module_instance.reply_to.assert_called_once_with(
            mock_message,
            f"ü§ñ‚ö†Ô∏è: {error_user_message}"
        )
        error_log_found = False
        for call_args, call_kwargs in mock_log_event.call_args_list:
            log_message = call_args[0]
            log_level = call_kwargs.get('level')
            if log_level == logging.ERROR and "NLP Error for module openai_chat" in log_message and "Original OpenAI Some Error" in log_message:
                self.assertTrue(call_kwargs.get('exc_info', False), "exc_info should be True for original_error logging")
                error_log_found = True
                break
        self.assertTrue(error_log_found, "Specific NLP error log message not found.")

    @patch('bot.katana_bot.log_local_bot_event')
    def test_handle_message_anthropic_chat_missing_prompt(self, mock_log_event):
        command_payload = {
            "type": "chat_query",
            "module": "anthropic_chat",
            "args": {}, # Missing "prompt"
            "id": "anthropic_missing_prompt"
        }
        mock_message = self._create_mock_message(command_payload)
        self.katana_bot.handle_message(mock_message)

        self.mock_bot_module_instance.reply_to.assert_called_once_with(
            mock_message,
            "‚ùå Error: 'prompt' is a required argument in 'args' for module 'anthropic_chat'."
        )
        # Check for error log
        error_log_found = False
        for call_args, call_kwargs in mock_log_event.call_args_list:
            if call_kwargs.get('level') == logging.ERROR and "Missing 'prompt' for anthropic_chat" in call_args[0]:
                error_log_found = True
                break
        self.assertTrue(error_log_found, "Error log for missing prompt not found.")

    @patch('bot.katana_bot.log_local_bot_event')
    def test_handle_message_openai_chat_missing_prompt(self, mock_log_event):
        command_payload = {
            "type": "chat_query",
            "module": "openai_chat",
            "args": {}, # Missing "prompt"
            "id": "openai_missing_prompt"
        }
        mock_message = self._create_mock_message(command_payload)
        self.katana_bot.handle_message(mock_message)

        self.mock_bot_module_instance.reply_to.assert_called_once_with(
            mock_message,
            "‚ùå Error: 'prompt' is a required argument in 'args' for module 'openai_chat'."
        )
        error_log_found = False
        for call_args, call_kwargs in mock_log_event.call_args_list:
            if call_kwargs.get('level') == logging.ERROR and "Missing 'prompt' for openai_chat" in call_args[0]:
                error_log_found = True
                break
        self.assertTrue(error_log_found, "Error log for missing prompt not found.")

    @patch('bot.katana_bot.get_anthropic_chat_response') # Patch one of the clients
    @patch('bot.katana_bot.log_local_bot_event')
    def test_handle_message_nlp_unexpected_error(self, mock_log_event, mock_get_anthropic_response):
        # Simulate an unexpected error (not NLPServiceError)
        simulated_error = KeyError("A very unexpected key error!")
        mock_get_anthropic_response.side_effect = simulated_error

        command_payload = {
            "type": "chat_query",
            "module": "anthropic_chat", # Using anthropic for this test
            "args": {"prompt": "This will cause an unexpected error"},
            "id": "unexpected_err_001"
        }
        mock_message = self._create_mock_message(command_payload)
        self.katana_bot.handle_message(mock_message)

        mock_get_anthropic_response.assert_called_once()

        # Verify bot replies with the generic internal error message
        self.mock_bot_module_instance.reply_to.assert_called_once_with(
            mock_message,
            "ü§ñ‚ö†Ô∏è: –ü—Ä–æ–∏–∑–æ—à–ª–∞ –≤–Ω—É—Ç—Ä–µ–Ω–Ω—è—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ –≤–∞—à–µ–≥–æ –∑–∞–ø—Ä–æ—Å–∞."
        )

        # Verify error logging for unexpected error
        error_log_found = False
        for call_args, call_kwargs in mock_log_event.call_args_list:
            log_message = call_args[0]
            log_level = call_kwargs.get('level')
            if log_level == logging.ERROR and "Unexpected error processing anthropic_chat" in log_message and str(simulated_error) in log_message:
                self.assertTrue(call_kwargs.get('exc_info', False), "exc_info should be True for unexpected errors")
                error_log_found = True
                break
        self.assertTrue(error_log_found, "Log for unexpected NLP error not found.")


    def test_unknown_command_type_saves_normally(self):
        command = {"type": "unknown_type", "module": "custom_module", "args": {}, "id": "custom003"}
        mock_message = self._create_mock_message(command)

        self.katana_bot.handle_message(mock_message)

        # Check file creation
        expected_module_dir = self.test_commands_dir / "telegram_mod_custom_module"
        self.assertTrue(expected_module_dir.exists())
        
        expected_filename = f"YYYYMMDD_HHMMSS_ffffff_{mock_message.chat.id}.json"
        expected_file_path = expected_module_dir / expected_filename
        self.assertTrue(expected_file_path.exists())

        with open(expected_file_path, "r") as f:
            saved_data = json.load(f)
        self.assertEqual(saved_data, command)

        # Check reply
        self.mock_bot_module_instance.reply_to.assert_called_once()
        args, kwargs = self.mock_bot_module_instance.reply_to.call_args
        self.assertEqual(args[0], mock_message)
        self.assertTrue(args[1].startswith("‚úÖ Command received and saved as"))
        self.assertIn(str(expected_file_path), args[1])


if __name__ == '__main__':
    unittest.main()
