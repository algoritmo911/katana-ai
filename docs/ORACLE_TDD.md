# Технический План Проекта "Оракул"

"Оракул" — это система тотального контроля и наблюдения за асинхронным миром "Хроноса". Этот документ описывает архитектуру "Центра Управления Полётами" (ЦУП).

---

## 1. Архитектура Наблюдения в Реальном Времени (`Real-Time Observability`)

Ключевая задача — обеспечить **мгновенное** отображение изменений состояния задач в браузере пользователя без необходимости постоянно опрашивать сервер (polling). Для этого мы спроектируем эффективный, push-ориентированный конвейер данных.

### 1.1. Технология Доставки: Server-Sent Events (SSE)

*   **Выбор:** **Server-Sent Events (SSE)**.
*   **Обоснование:**
    *   **Простота и Адекватность:** SSE — это стандарт W3C, предназначенный для **однонаправленной** передачи данных от сервера к клиенту. Это в точности соответствует нашей основной задаче: сервер должен уведомлять браузер об изменении статуса задачи. В отличие от WebSockets, SSE работает поверх стандартного HTTP, не требует сложного установления соединения и проще в реализации и отладке.
    *   **Надежность:** Стандарт SSE включает механизм автоматического переподключения клиента в случае разрыва соединения, что снижает сложность клиентского кода.
    *   **Масштабируемость:** Для нашего сценария (сотни или тысячи одновременных подключений для наблюдения) SSE является более легковесным и менее ресурсоемким решением по сравнению с полнодуплексными WebSockets.
    *   **Почему не WebSockets?** WebSockets — это более мощный, **двунаправленный** протокол, который является избыточным для простого отображения статусов. Управляющие команды от клиента (отмена, перезапуск) являются редкими, асинхронными действиями и могут быть эффективно реализованы через стандартные REST API вызовы (POST/DELETE), что делает ненужным постоянное дуплексное соединение.

### 1.2. Конвейер Данных (Data Pipeline)

Мы реализуем следующий конвейер для доставки обновлений от базы данных до браузера с минимальной задержкой:

1.  **Источник Истины (СУБД):** Любое изменение состояния задачи (например, `pending` -> `in_progress`) происходит в транзакции в базе данных **PostgreSQL**.

2.  **Механизм Уведомления (`NOTIFY/LISTEN`):**
    *   Внутри той же транзакции, где Celery воркер обновляет статус задачи, будет вызываться функция PostgreSQL, которая выполняет команду `NOTIFY`.
    *   Пример: `SELECT pg_notify('oracle_channel', '{"task_id": "...", "new_status": "in_progress", "timestamp": "..."}');`
    *   Это отправляет сообщение с JSON-payload в именованный канал `oracle_channel` всем, кто его слушает. `pg_notify` является транзакционным и гарантирует, что уведомление будет отправлено только после успешного коммита транзакции.

3.  **Сервис-Вещатель (`Broadcaster`):**
    *   Это будет специализированный, легковесный сервис (или фоновая задача в основном FastAPI-приложении), написанный на Python с использованием `asyncio`.
    *   При старте он устанавливает постоянное соединение с PostgreSQL и выполняет команду `LISTEN oracle_channel`.
    *   Он также будет управлять пулом активных SSE-подключений от клиентов (браузеров). Каждое подключение будет ассоциировано с `user_id`, чтобы отправлять только релевантные уведомления.

4.  **Доставка Клиенту (SSE):**
    *   Когда `Broadcaster` получает уведомление по каналу `oracle_channel`, он парсит JSON-payload.
    *   Он находит все активные SSE-соединения, которые должны получить это обновление (например, все соединения от владельца задачи и всех администраторов).
    *   Он отправляет полученные данные в виде SSE-события каждому из этих клиентов.

5.  **Отображение (Frontend):**
    *   Клиентское приложение (в браузере) устанавливает EventSource-соединение с эндпоинтом `/api/tasks/subscribe`.
    *   Оно слушает входящие события и, при получении нового, мгновенно обновляет DOM для отображения нового статуса задачи, лога или результата.

Эта архитектура создает реактивную, управляемую событиями систему, где база данных является центральным источником событий, что гарантирует консистентность данных и высокую производительность.

## 2. Проектирование "Пульта Управления" (UI/UX и Control Plane)

"Центр Управления Полётами" (ЦУП) должен быть не просто набором данных, а интуитивно понятным и функциональным инструментом.

### 2.1. Концепция Пользовательского Интерфейса (UI/UX)

Интерфейс будет представлять собой одностраничное приложение (SPA), разделенное на три основные области:

1.  **Панель Метрик (Header):**
    *   Располагается вверху страницы.
    *   Отображает ключевые метрики в реальном времени: `Задач в очереди`, `Активных задач`, `Процент сбоев (24ч)`, `Среднее время выполнения (24ч)`.
    *   Для администраторов здесь же будут кнопки управления всей системой: `Приостановить очередь` / `Возобновить очередь`.

2.  **Список Задач (Master View):**
    *   Основная область слева. Представляет собой "живую" таблицу со списком всех задач.
    *   **Колонки:** `ID Задачи`, `Имя Задачи`, `Статус` (цветная метка), `Пользователь`, `Время Создания`.
    *   **Функционал:**
        *   **Фильтрация:** По статусу, имени задачи, пользователю.
        *   **Поиск:** По ID задачи.
        *   **Сортировка:** По любой из колонок.
        *   **Real-time обновления:** Новые задачи появляются вверху списка, статусы существующих задач меняются "на лету" без перезагрузки страницы (благодаря SSE).

3.  **Детальный Вид Задачи (Detail View):**
    *   Область справа. Появляется при клике на задачу в Master View.
    *   **Содержимое:**
        *   **Заголовок:** Полный ID и имя задачи.
        *   **Текущий статус:** Крупно и наглядно.
        *   **Панель управления задачей:** Кнопки `Перезапустить` (если статус `failed`) и `Отменить` (если статус `pending` или `in_progress`).
        *   **История состояний:** Лог всех переходов статусов с временными метками (e.g., `pending -> in_progress (1.2s)`, `in_progress -> completed (34.5s)`).
        *   **Логи выполнения:** Поток логов от Celery воркера, относящихся к данной задаче (также обновляется в реальном времени через SSE).
        *   **Результат:** Если задача `completed`, здесь отображается `result_payload` в отформатированном виде (например, как JSON или ссылка на файл). Если `failed` — отображается `error_message`.

### 2.2. Панель Управления (Control Plane API)

Для реализации управляющих функций будет создана группа REST API эндпоинтов.

*   `POST /api/tasks/{task_id}/retry`
    *   **Действие:** Перезапускает задачу, которая завершилась с ошибкой.
    *   **Логика:** Бэкенд находит задачу в БД, проверяет ее статус (`failed`). Если проверка успешна, создает и отправляет новое сообщение в RabbitMQ с параметрами оригинальной задачи.
    *   **Безопасность:** Доступно только владельцу задачи или администратору.

*   `DELETE /api/tasks/{task_id}`
    *   **Действие:** Отменяет выполнение задачи.
    *   **Логика:**
        *   Если задача `pending`: сообщение удаляется из очереди RabbitMQ (если это возможно) и статус в БД меняется на `cancelled`.
        *   Если задача `in_progress`: Celery получает сигнал на отмену (`revoke`). Воркер должен быть написан так, чтобы корректно обработать этот сигнал (например, прекратить выполнение и выполнить очистку). Статус в БД меняется на `cancelled`.
    *   **Безопасность:** Доступно только владельцу задачи или администратору.

*   `POST /api/admin/queue/pause`
    *   **Действие:** Приостанавливает обработку задач из основной очереди.
    *   **Логика:** Использует средства Celery или RabbitMQ для остановки потребления сообщений воркерами.
    *   **Безопасность:** Доступно только администраторам.

*   `POST /api/admin/queue/resume`
    *   **Действие:** Возобновляет обработку задач.
    *   **Логика:** Отменяет действие предыдущей команды.
    *   **Безопасность:** Доступно только администраторам.

### 2.3. Безопасность

*   **Аутентификация:** API ЦУП будет защищен. Доступ будет осуществляться по JWT-токенам, которые могут быть получены через основную систему аутентификации проекта.
*   **Авторизация:**
    *   **Владелец задачи:** Пользователь может видеть и управлять только своими задачами. Каждый API-запрос будет проверять, что `user_id` из JWT-токена совпадает с `user_id` в записи о задаче.
    *   **Администратор:** Пользователи с ролью `admin` имеют доступ ко всем задачам и административным эндпоинтам (`/api/admin/*`).

## 3. Интеграция с Распределённой Трассировкой

Проблема "чёрного ящика" не ограничивается только статусом задачи. Если задача взаимодействует с другими микросервисами, нам необходимо видеть полный путь её выполнения, чтобы быстро диагностировать узкие места и точки отказа.

### 3.1. Технология: OpenTelemetry

*   **Выбор:** **OpenTelemetry (OTel)**.
*   **Обоснование:** OTel — это современный, вендор-нейтральный стандарт для сбора телеметрии (трассировок, метрик, логов). Он поддерживается всеми основными облачными провайдерами и системами мониторинга (Jaeger, Zipkin, Datadog). Использование OTel вместо проприетарного решения обеспечивает гибкость и возможность смены бэкенда для хранения и визуализации трейсов в будущем.

### 3.2. Сквозная Пропаганда Контекста Трассировки

Цель — связать `trace_id`, сгенерированный при получении вебхука в FastAPI, с операциями, выполняемыми в Celery воркере, даже если между ними находится брокер сообщений.

1.  **Генерация `trace_id` (FastAPI):**
    *   Наш существующий `LoggingMiddleware` из проекта "Симбиот" уже генерирует `trace_id` (мы можем назвать его `correlation_id` для ясности).
    *   Мы дополним его OTel-инструментацией для FastAPI. При получении входящего HTTP-запроса будет создаваться корневой "спан" (root span). Наш `correlation_id` будет добавлен к этому спану в качестве атрибута.

2.  **Инъекция в Брокер Сообщений:**
    *   Перед отправкой сообщения в RabbitMQ, FastAPI-сервис будет **инъецировать** контекст трассировки (включающий `trace_id` и `span_id`) в заголовки сообщения.
    *   Celery имеет встроенную поддержку для автоматической пропаганды контекста OTel. Мы просто должны будем её включить и настроить.

3.  **Экстракция в Воркере (Celery):**
    *   Когда Celery воркер получает сообщение из RabbitMQ, он автоматически **экстрагирует** контекст трассировки из заголовков.
    *   Он создает новый "спан" для выполнения задачи, делая его дочерним по отношению к корневому спану, созданному в FastAPI. Это автоматически связывает их в единый трейс.

4.  **Трассировка Внутренних Операций:**
    *   Внутри самого воркера мы можем создавать дополнительные дочерние спаны для отслеживания ключевых операций: `db_query`, `external_api_call` и т.д. OTel-инструментация для популярных библиотек (таких как `SQLAlchemy`, `httpx`) может делать это автоматически.

### 3.3. Визуализация в "Оракуле"

*   **Хранение `trace_id`:** `trace_id`, сгенерированный OTel, будет сохранен в нашей базе данных PostgreSQL в записи о задаче (`TaskStateRecord`).
*   **Интеграция с UI:**
    *   В детальном виде задачи в ЦУП будет поле "Trace ID".
    *   Рядом с ним будет кнопка **"Посмотреть трейс"**.
    *   Эта кнопка будет являться ссылкой, ведущей напрямую на страницу данного трейса в нашей системе визуализации (например, Jaeger). URL будет иметь вид: `https://jaeger.наш-домен.com/trace/{trace_id}`.

Таким образом, мы получаем бесшовную интеграцию, позволяющую одним кликом перейти от конкретной задачи в "Оракуле" к детальному "водопаду" её выполнения в системе распределенной трассировки, полностью решая проблему "осознания" на всех уровнях.
